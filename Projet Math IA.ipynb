{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b4e4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting page 1...\n",
      "Found 35 listings on page 1\n",
      "Page 1 scraped successfully. Total listings: 34\n",
      "Waiting 6.7 seconds...\n",
      "Requesting page 2...\n",
      "Found 5 listings on page 2\n",
      "Page 2 scraped successfully. Total listings: 37\n",
      "Waiting 7.3 seconds...\n",
      "Requesting page 3...\n",
      "Found 35 listings on page 3\n",
      "Page 3 scraped successfully. Total listings: 71\n",
      "Waiting 7.9 seconds...\n",
      "Requesting page 4...\n",
      "Found 5 listings on page 4\n",
      "Page 4 scraped successfully. Total listings: 74\n",
      "Waiting 8.6 seconds...\n",
      "Requesting page 5...\n",
      "Found 35 listings on page 5\n",
      "Page 5 scraped successfully. Total listings: 108\n",
      "Waiting 9.2 seconds...\n",
      "Requesting page 6...\n",
      "Found 5 listings on page 6\n",
      "Page 6 scraped successfully. Total listings: 111\n",
      "Waiting 9.8 seconds...\n",
      "Requesting page 7...\n",
      "Found 5 listings on page 7\n",
      "Page 7 scraped successfully. Total listings: 114\n",
      "Waiting 10.4 seconds...\n",
      "Requesting page 8...\n",
      "Found 35 listings on page 8\n",
      "Page 8 scraped successfully. Total listings: 148\n",
      "Waiting 11.0 seconds...\n",
      "Requesting page 9...\n",
      "Found 5 listings on page 9\n",
      "Page 9 scraped successfully. Total listings: 151\n",
      "Reached target of 151 listings (min 150). Stopping.\n",
      "Initial dataset size: 151\n",
      "After removing duplicates: 141\n",
      "After removing rows with missing title and price: 141\n",
      "After removing price outliers: 64\n",
      "After removing surface outliers: 60\n",
      "\n",
      "Success! Saved 60 listings to mubawab_properties_150_to_200_rows.csv\n",
      "EDA plots saved in eda_plots\n",
      "Dataset for modeling: 60 rows\n",
      "\n",
      "Model Evaluation:\n",
      "R² Score: 0.1204\n",
      "RMSE: 1138355.48 DH\n",
      "MAE: 909240.87 DH\n",
      "\n",
      "Feature Importance (Regression Coefficients):\n",
      "                                              Feature   Coefficient\n",
      "19                  location_tanger city center. 6...  1.509637e+06\n",
      "17                                location_Val Fleuri -1.138156e+06\n",
      "3                location_Branes Kdima. 5 chambres... -8.969082e+05\n",
      "18              location_View Tower. Superficie 81 m²  8.718411e+05\n",
      "14  location_Tanger City Center. 3 chambres. Anten...  5.942015e+05\n",
      "5         location_El Baraka. Superficie 58 m². Be... -5.175955e+05\n",
      "1                                             surface  4.995095e+05\n",
      "7                             location_Malabata Hills  4.952765e+05\n",
      "16                 location_Tanger. 2 belles chambres -4.698000e+05\n",
      "12        location_Route Nationale Assilah. 2 cham... -4.693132e+05\n",
      "6   location_Ghandouri. 3 chambres. Piscine, clima...  3.489719e+05\n",
      "22                                        type_Maison  3.122485e+05\n",
      "15                       location_Tanger centre ville  2.804600e+05\n",
      "2                                           location_ -2.783957e+05\n",
      "11                                location_Rico Costa -2.588264e+05\n",
      "21                                         type_Autre -2.369212e+05\n",
      "0                                            bedrooms  1.867516e+05\n",
      "9                             location_Mesnana Tanger -7.816359e+04\n",
      "20                                   type_Appartement -7.532727e+04\n",
      "13                                    location_Tanger  6.565770e+04\n",
      "10                             location_Mesnna Tanger -4.017048e+04\n",
      "8                                    location_Mesnana -2.014708e+04\n",
      "4                                   location_Castilla  1.430837e+03\n",
      "\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from fake_useragent import UserAgent\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "BASE_URL = \"https://www.mubawab.ma\"\n",
    "SEARCH_URL = f\"{BASE_URL}/fr/ct/tanger/immobilier-a-vendre\"\n",
    "MAX_LISTINGS = 200\n",
    "MIN_LISTINGS = 150\n",
    "OUTPUT_FILE = \"mubawab_properties_150_to_200_rows.csv\"\n",
    "PLOT_DIR = \"eda_plots\"\n",
    "DELAY = random.uniform(5, 10)\n",
    "TIMEOUT = 20\n",
    "\n",
    "# Rotating user agents\n",
    "ua = UserAgent()\n",
    "\n",
    "def get_headers():\n",
    "    return {\n",
    "        'User-Agent': ua.random,\n",
    "        'Accept-Language': 'fr-FR,fr;q=0.9',\n",
    "        'Referer': BASE_URL,\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,/;q=0.8',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Connection': 'keep-alive',\n",
    "        'DNT': '1'\n",
    "    }\n",
    "\n",
    "def extract_price(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    text = text.replace(' ', '').replace(',', '').replace('\\xa0', '')\n",
    "    match = re.search(r'(\\d[\\d\\s]*\\.?\\d+)', text)\n",
    "    return float(match.group(1).replace(' ', '')) if match else None\n",
    "\n",
    "def parse_listing(listing):\n",
    "    result = {\n",
    "        'title': None,\n",
    "        'price': None,\n",
    "        'bedrooms': None,\n",
    "        'surface': None,\n",
    "        'location': None,\n",
    "        'url': None,\n",
    "        'type': None,\n",
    "        'scraped_at': pd.Timestamp.now()\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        title_elem = listing.find('h2', class_=re.compile('listingTit|title'))\n",
    "        if not title_elem:\n",
    "            title_elem = listing.find('h2') or listing.find(class_=re.compile('title|heading'))\n",
    "        result['title'] = title_elem.get_text(strip=True) if title_elem else None\n",
    "\n",
    "        price_elem = listing.find(class_=re.compile('priceTag|price|cost'))\n",
    "        if not price_elem:\n",
    "            price_elem = listing.find(string=re.compile('DH|MAD|€|Dhs'))\n",
    "        price_text = price_elem.get_text(strip=True) if price_elem else \"\"\n",
    "        result['price'] = extract_price(price_text)\n",
    "\n",
    "        link = listing.find('a', href=True)\n",
    "        if link and link['href']:\n",
    "            result['url'] = BASE_URL + link['href'] if not link['href'].startswith('http') else link['href']\n",
    "\n",
    "        card_text = listing.get_text(' ')\n",
    "        \n",
    "        bedrooms = re.search(r'(\\d+)\\s*(?:chambres?|pieces?)', card_text, re.IGNORECASE)\n",
    "        result['bedrooms'] = int(bedrooms.group(1)) if bedrooms else None\n",
    "        \n",
    "        surface = re.search(r'(\\d+)\\s*(?:m²|m2|m\\s*²)', card_text, re.IGNORECASE)\n",
    "        result['surface'] = int(surface.group(1)) if surface else None\n",
    "        \n",
    "        if result['title'] and 'à' in result['title']:\n",
    "            result['location'] = result['title'].split('à')[-1].strip()\n",
    "        else:\n",
    "            location_elem = listing.find(class_=re.compile('location|ville|place'))\n",
    "            result['location'] = location_elem.get_text(strip=True) if location_elem else None\n",
    "\n",
    "        if result['title']:\n",
    "            title_lower = result['title'].lower()\n",
    "            if 'appartement' in title_lower:\n",
    "                result['type'] = 'Appartement'\n",
    "            elif 'maison' in title_lower or 'villa' in title_lower:\n",
    "                result['type'] = 'Maison'\n",
    "            else:\n",
    "                result['type'] = 'Autre'\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing listing: {e}\")\n",
    "        return None\n",
    "    \n",
    "    if result['title'] or result['price']:\n",
    "        return result\n",
    "    return None\n",
    "\n",
    "def scrape_page(page_num):\n",
    "    try:\n",
    "        url = f\"{SEARCH_URL}:p:{page_num}\" if page_num > 1 else SEARCH_URL\n",
    "        print(f\"Requesting page {page_num}...\")\n",
    "        \n",
    "        response = requests.get(url, headers=get_headers(), timeout=TIMEOUT)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Request failed with status {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        listings = soup.find_all('li', class_=re.compile('listingBox|propertyBox|listing'))\n",
    "        if not listings:\n",
    "            listings = soup.select('div.listingBox, div.propertyBox, section.property')\n",
    "        if not listings:\n",
    "            listings = soup.find_all(class_=re.compile('listing|property'))\n",
    "        \n",
    "        print(f\"Found {len(listings)} listings on page {page_num}\")\n",
    "        return [parse_listing(l) for l in listings if parse_listing(l) is not None]\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error on page {page_num}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping page {page_num}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_data_pipeline():\n",
    "    numeric_features = ['bedrooms', 'surface']\n",
    "    categorical_features = ['location', 'type']\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 2.0 * IQR\n",
    "    upper_bound = Q3 + 2.0 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "def perform_eda(df):\n",
    "    os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['price'].dropna(), kde=True)\n",
    "    plt.title('Distribution des Prix')\n",
    "    plt.xlabel('Prix (DH)')\n",
    "    plt.ylabel('Fréquence')\n",
    "    plt.savefig(f\"{PLOT_DIR}/price_distribution.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(y=df['price'].dropna())\n",
    "    plt.title('Boxplot des Prix')\n",
    "    plt.ylabel('Prix (DH)')\n",
    "    plt.savefig(f\"{PLOT_DIR}/price_boxplot.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='surface', y='price', hue='type', size='bedrooms', data=df)\n",
    "    plt.title('Prix vs Surface')\n",
    "    plt.xlabel('Surface (m²)')\n",
    "    plt.ylabel('Prix (DH)')\n",
    "    plt.savefig(f\"{PLOT_DIR}/price_vs_surface.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    numeric_cols = ['price', 'bedrooms', 'surface']\n",
    "    sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Matrice de Corrélation')\n",
    "    plt.savefig(f\"{PLOT_DIR}/correlation_matrix.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='location', y='price', data=df)\n",
    "    plt.title('Prix par Localisation')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(f\"{PLOT_DIR}/price_by_location.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='type', y='price', data=df)\n",
    "    plt.title('Prix par Type de Bien')\n",
    "    plt.xlabel('Type')\n",
    "    plt.ylabel('Prix (DH)')\n",
    "    plt.savefig(f\"{PLOT_DIR}/price_by_type.png\")\n",
    "    plt.close()\n",
    "\n",
    "def train_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', create_data_pipeline()),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.2f} DH\")\n",
    "    print(f\"MAE: {mae:.2f} DH\")\n",
    "    \n",
    "    preprocessor = model_pipeline.named_steps['preprocessor']\n",
    "    regressor = model_pipeline.named_steps['regressor']\n",
    "    numeric_features = ['bedrooms', 'surface']\n",
    "    categorical_features = ['location', 'type']\n",
    "    feature_names = (numeric_features + \n",
    "                     preprocessor.named_transformers_['cat']\n",
    "                     .named_steps['onehot']\n",
    "                     .get_feature_names_out(categorical_features).tolist())\n",
    "    \n",
    "    coefficients = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Coefficient': regressor.coef_\n",
    "    })\n",
    "    print(\"\\nFeature Importance (Regression Coefficients):\")\n",
    "    print(coefficients.sort_values(by='Coefficient', key=abs, ascending=False))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Coefficient', y='Feature', data=coefficients)\n",
    "    plt.title('Importance des variables (coefficients)')\n",
    "    plt.xlabel('Coefficient')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.savefig(f\"{PLOT_DIR}/feature_importance_linear.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return model_pipeline\n",
    "\n",
    "def main():\n",
    "    all_data = []\n",
    "    page_num = 1\n",
    "    \n",
    "    while len(all_data) < MAX_LISTINGS:\n",
    "        page_data = scrape_page(page_num)\n",
    "        if page_data:\n",
    "            all_data.extend(page_data)\n",
    "            print(f\"Page {page_num} scraped successfully. Total listings: {len(all_data)}\")\n",
    "            \n",
    "            if len(all_data) >= MIN_LISTINGS:\n",
    "                print(f\"Reached target of {len(all_data)} listings (min {MIN_LISTINGS}). Stopping.\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Failed to scrape page {page_num}\")\n",
    "        \n",
    "        wait_time = DELAY * (1 + page_num/10)\n",
    "        print(f\"Waiting {wait_time:.1f} seconds...\")\n",
    "        time.sleep(wait_time)\n",
    "        \n",
    "        if page_num > 10 and len(all_data) < MIN_LISTINGS:\n",
    "            print(\"Stopping - likely blocked or no more listings\")\n",
    "            break\n",
    "        \n",
    "        page_num += 1\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"FAILED - No data collected.\")\n",
    "        return\n",
    "    \n",
    "    if len(all_data) > MAX_LISTINGS:\n",
    "        all_data = all_data[:MAX_LISTINGS]\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    print(f\"Initial dataset size: {len(df)}\")\n",
    "    \n",
    "    df = df.drop_duplicates(subset=['url'], keep='first')\n",
    "    print(f\"After removing duplicates: {len(df)}\")\n",
    "    \n",
    "    df = df[df['title'].notna() | df['price'].notna()]\n",
    "    print(f\"After removing rows with missing title and price: {len(df)}\")\n",
    "    \n",
    "    df = handle_outliers(df, 'price')\n",
    "    print(f\"After removing price outliers: {len(df)}\")\n",
    "    \n",
    "    df = handle_outliers(df, 'surface')\n",
    "    print(f\"After removing surface outliers: {len(df)}\")\n",
    "    \n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"\\nSuccess! Saved {len(df)} listings to {OUTPUT_FILE}\")\n",
    "    \n",
    "    perform_eda(df)\n",
    "    print(f\"EDA plots saved in {PLOT_DIR}\")\n",
    "    \n",
    "    features = ['bedrooms', 'surface', 'location', 'type']\n",
    "    X = df[features]\n",
    "    y = df['price'].dropna()\n",
    "    X = X.loc[y.index]\n",
    "    print(f\"Dataset for modeling: {len(X)} rows\")\n",
    "    \n",
    "    model = train_model(X, y)\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
